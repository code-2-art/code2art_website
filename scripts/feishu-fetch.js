// Node 18+ (åŸç”Ÿ fetch)
// ç”¨æ³•ï¼šnode scripts/feishu-fetch.js
// ä»ã€Œåšå®¢ä¸»è¡¨ã€æŠ“å–æ•°æ® â†’ ç”Ÿæˆ src/content/posts/{slug}.md
import 'dotenv/config';
import fs from 'node:fs';
import path from 'node:path';
import {
  env, FIELD, listAllRecords, toUrlMaybe,
  download, enrichContentHtmlFromDocIfNeeded, mapRecordBase,
  getTenantAccessToken,
} from './feishu-common.js';
import { htmlToMarkdown, buildMarkdownFile } from './markdown-util.js';

const OUT_DIR = 'src/content/posts';
const ASSET_DIR = 'public/uploads';
const DOWNLOAD_ASSETS = process.env.DOWNLOAD_ASSETS === '1';

function mapRecord(rec, contentHtmlResolved) {
  const base = mapRecordBase(rec, contentHtmlResolved);
  const f = rec.fields || rec;
  return {
    ...base,
    docUrl: toUrlMaybe(f[FIELD.docUrl]) ?? undefined,
    publishedAt: f[FIELD.publishedAt] ?? undefined,
  };
}

async function localizeHtmlImages(html) {
  if (!html || !DOWNLOAD_ASSETS) return html;
  const re = /<img\b[^>]*?src=["']([^"']+)["'][^>]*?>/gi;
  const replacements = [];
  let m;
  while ((m = re.exec(html)) !== null) {
    const src = m[1];
    if (typeof src !== 'string') continue;
    if (!/^https?:\/\//i.test(src)) continue;
    try {
      const local = await download(src, ASSET_DIR);
      replacements.push({ from: src, to: local });
    } catch (e) {
      console.warn('embed image download failed:', src, e.message);
    }
  }
  let out = html;
  for (const r of replacements) {
    out = out.split(r.from).join(r.to);
  }
  return out;
}

async function main() {
  const token = await getTenantAccessToken(env('FEISHU_APP_ID'), env('FEISHU_APP_SECRET'));
  const items = await listAllRecords({
    appToken: env('FEISHU_APP_TOKEN'),
    tableId: env('FEISHU_TABLE_ID'),
    viewId: process.env.FEISHU_VIEW_ID,
  });

  const posts = [];
  for (const it of items) {
    let html = await enrichContentHtmlFromDocIfNeeded(it, token);
    if (DOWNLOAD_ASSETS) {
      html = await localizeHtmlImages(html);
    }
    posts.push(mapRecord(it, html));
  }

  posts.sort((a, b) => new Date(b.publishedAt ?? 0) - new Date(a.publishedAt ?? 0));

  if (DOWNLOAD_ASSETS) {
    for (const p of posts) {
      if (typeof p.coverUrl === 'string' && p.coverUrl.startsWith('http')) {
        try { p.coverUrl = await download(p.coverUrl, ASSET_DIR); } catch (e) { console.warn('cover download failed:', p.coverUrl, e.message); }
      }
      if (typeof p.authorAvatarUrl === 'string' && p.authorAvatarUrl.startsWith('http')) {
        try { p.authorAvatarUrl = await download(p.authorAvatarUrl, ASSET_DIR); } catch (e) { console.warn('avatar download failed:', p.authorAvatarUrl, e.message); }
      }
    }
  }

  fs.mkdirSync(OUT_DIR, { recursive: true });

  const writtenFiles = new Set();
  for (const p of posts) {
    const frontmatter = {
      title: p.title,
      slug: p.slug,
      source: 'feishu',
      summary: p.summary,
      coverUrl: p.coverUrl,
      tags: p.tags,
      author: p.author,
      authorAvatarUrl: p.authorAvatarUrl,
      publishedAt: p.publishedAt,
      docUrl: p.docUrl,
    };
    const body = htmlToMarkdown(p.contentHtml || '');
    const md = buildMarkdownFile(frontmatter, body);
    const filename = `${p.slug}.md`;
    fs.writeFileSync(path.join(OUT_DIR, filename), md, 'utf-8');
    writtenFiles.add(filename);
  }

  // Remove stale fetched .md files that no longer exist upstream.
  // Only delete files generated by this script (source: "feishu") so that
  // locally authored or other-platform Markdown files are preserved.
  for (const f of fs.readdirSync(OUT_DIR)) {
    if (f.endsWith('.md') && !writtenFiles.has(f)) {
      const content = fs.readFileSync(path.join(OUT_DIR, f), 'utf-8');
      if (/^source:\s*["']?feishu["']?\s*$/m.test(content)) {
        fs.unlinkSync(path.join(OUT_DIR, f));
        console.log(`ğŸ—‘  Removed stale file: ${f}`);
      }
    }
  }

  console.log(`âœ… Wrote ${posts.length} posts â†’ ${OUT_DIR}/`);
}

main().catch((e) => { console.error(e); process.exit(1); });
